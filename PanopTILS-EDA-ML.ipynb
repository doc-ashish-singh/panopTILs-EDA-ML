{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f308979-6364-4ac7-80ac-12492f952a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import shutil\n",
    "\n",
    "# Exploring labels in the PanopTILs dataset\n",
    "\n",
    "folder_path = \"/Users/ashishsingh/Desktop/csv\"\n",
    "\n",
    "# Initialize sets to store unique values across all files\n",
    "all_raw_group = set()\n",
    "all_group = set()\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # Check if the file is a CSV\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Load the CSV file\n",
    "        data = pd.read_csv(file_path)\n",
    "        \n",
    "        # Add unique values from current file to the sets\n",
    "        all_raw_group.update(data['raw_group'].unique())\n",
    "        all_group.update(data['group'].unique())\n",
    "\n",
    "# Print the concatenated unique values\n",
    "print(\"Concatenated unique values in 'raw_group' column across all files:\")\n",
    "print(all_raw_group)\n",
    "\n",
    "print(\"\\nConcatenated unique values in 'group' column across all files:\")\n",
    "print(all_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f2a09e-9e28-4ccb-bfee-a3b1ab9a489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of files in each of the four PanopTILs folder\n",
    "\n",
    "rgb_dir = \"/Users/ashishsingh/Desktop/rgbs\"  # path to RGB WSI folder\n",
    "mask_dir = \"/Users/ashishsingh/Desktop/masks\"  # path to masks folder\n",
    "csv_dir = \"/Users/ashishsingh/Desktop/csv\"  # path to CSV folder\n",
    "vis_dir = \"/Users/ashishsingh/Desktop/vis\"  # path to visualisation images folder\n",
    "\n",
    "# Display dataset information\n",
    "print(f\"Number of RGB images: {len(os.listdir(rgb_dir))}\")\n",
    "print(f\"Number of masks: {len(os.listdir(mask_dir))}\")\n",
    "print(f\"Number of CSV files: {len(os.listdir(csv_dir))}\")\n",
    "print(f\"Number of visualizations: {len(os.listdir(vis_dir))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7ee1de-0727-4b3e-a2dd-a53c8a3b5fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the CSV folder and files in more detail\n",
    "\n",
    "csv_file_path = \"/Users/ashishsingh/Desktop/ALL_FOV_LOCATIONS.csv\"\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Find unique values in 'raw_group' and 'group' columns\n",
    "number_of_unique_roiname = data['roiname'].nunique()\n",
    "unique_roiname = data['roiname'].unique()\n",
    "\n",
    "# Print the unique values\n",
    "print(\"Number of unqiue values in 'roiname' column:\")\n",
    "print(number_of_unique_roiname)\n",
    "\n",
    "print(\"Unique values in 'roiname' column:\")\n",
    "print(unique_roiname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbddd3b-64bf-4544-b58f-942987adaa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and verifying four 'filtered' folders, each containing 1316 files\n",
    "\n",
    "# Paths to new filtered folders on Desktop\n",
    "desktop_path = os.path.expanduser(\"~/Desktop\")\n",
    "filtered_rgb_dir = os.path.join(desktop_path, \"filtered_rgbs\")\n",
    "filtered_mask_dir = os.path.join(desktop_path, \"filtered_masks\")\n",
    "filtered_csv_dir = os.path.join(desktop_path, \"filtered_csvs\")\n",
    "filtered_vis_dir = os.path.join(desktop_path, \"filtered_visualizations\")\n",
    "\n",
    "# Create new filtered folders\n",
    "os.makedirs(filtered_rgb_dir, exist_ok=True)\n",
    "os.makedirs(filtered_mask_dir, exist_ok=True)\n",
    "os.makedirs(filtered_csv_dir, exist_ok=True)\n",
    "os.makedirs(filtered_vis_dir, exist_ok=True)\n",
    "\n",
    "# Get base names (without extensions) from each folder\n",
    "rgb_files = {os.path.splitext(file)[0] for file in os.listdir(rgb_dir) if file.endswith(\".png\")}\n",
    "mask_files = {os.path.splitext(file)[0].replace(\"-mask\", \"\") for file in os.listdir(mask_dir) if file.endswith(\".png\")}\n",
    "csv_files = {os.path.splitext(file)[0] for file in os.listdir(csv_dir) if file.endswith(\".csv\")}\n",
    "vis_files = {os.path.splitext(file)[0].replace(\"-viz\", \"\") for file in os.listdir(vis_dir) if file.endswith(\".png\")}\n",
    "\n",
    "# Find common base names across all folders\n",
    "common_files = rgb_files & mask_files & csv_files & vis_files\n",
    "\n",
    "print(f\"Number of common files across all folders: {len(common_files)}\")\n",
    "\n",
    "# Helper function to filter files based on common names\n",
    "def filter_and_copy_files(source_dir, dest_dir, file_extension, suffix=\"\"):\n",
    "    for file_name in os.listdir(source_dir):\n",
    "        base_name = os.path.splitext(file_name)[0].replace(suffix, \"\")\n",
    "        if base_name in common_files:\n",
    "            src_path = os.path.join(source_dir, file_name)\n",
    "            dest_path = os.path.join(dest_dir, file_name)\n",
    "            shutil.copy(src_path, dest_path)\n",
    "\n",
    "# Filter and copy files to new folders\n",
    "filter_and_copy_files(rgb_dir, filtered_rgb_dir, \".png\")\n",
    "filter_and_copy_files(mask_dir, filtered_mask_dir, \".png\", suffix=\"-mask\")\n",
    "filter_and_copy_files(csv_dir, filtered_csv_dir, \".csv\")\n",
    "filter_and_copy_files(vis_dir, filtered_vis_dir, \".png\", suffix=\"-viz\")\n",
    "\n",
    "print(f\"\\nFiltered files have been saved to the following directories on your Desktop:\")\n",
    "print(f\"Filtered RGBs: {filtered_rgb_dir}\")\n",
    "print(f\"Filtered Masks: {filtered_mask_dir}\")\n",
    "print(f\"Filtered CSVs: {filtered_csv_dir}\")\n",
    "print(f\"Filtered Visualizations: {filtered_vis_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb798ce2-6a72-4798-92ac-d73dc9fb7a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further verifying all roinames in csv file correspond to RGB WSI files\n",
    "\n",
    "csv_file_path = \"/Users/ashishsingh/Desktop/ALL_FOV_LOCATIONS.csv\"\n",
    "rgb_folder_path = \"/Users/ashishsingh/Desktop/filtered_rgbs\"\n",
    "\n",
    "try:\n",
    "    # Load the main CSV file and check for the \"roiname\" column\n",
    "    csv_data = pd.read_csv(csv_file_path)\n",
    "    if \"roiname\" not in csv_data.columns:\n",
    "        raise ValueError(\"The 'roiname' column is not found in the CSV file.\")\n",
    "    \n",
    "    # Extract unique \"roiname\" values from the main CSV file and append \".png\"\n",
    "    csv_roinames = {f\"{roiname}\" for roiname in csv_data['roiname'].unique()}\n",
    "\n",
    "    # Get the list of file names (with extensions) in the RGB folder\n",
    "    rgb_files = {file for file in os.listdir(rgb_folder_path) if file.endswith(\".png\")}\n",
    "\n",
    "    # Find the \"roiname\" values that do not match the RGB file names\n",
    "    non_matching_roinames = csv_roinames - rgb_files\n",
    "\n",
    "    # Display the results\n",
    "    if non_matching_roinames:\n",
    "        print(f\"Number of non-matching 'roiname' entries: {len(non_matching_roinames)}\")\n",
    "        print(\"Non-matching 'roiname' entries:\")\n",
    "        for roiname in non_matching_roinames:\n",
    "            print(roiname)\n",
    "    else:\n",
    "        print(\"All 'roiname' entries match the file names in the RGB folder.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61d7da4-3595-4aac-9f07-c5b1e321fa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final check of all files across the four PanopTILs folder\n",
    "\n",
    "rgb_dir = \"/Users/ashishsingh/Desktop/filtered_rgbs\"  # Replace with the path to your RGB images folder\n",
    "mask_dir = \"/Users/ashishsingh/Desktop/filtered_masks\"  # Replace with the path to your masks folder\n",
    "csv_dir = \"/Users/ashishsingh/Desktop/filtered_csvs\"  # Replace with the path to your CSV folder\n",
    "vis_dir = \"/Users/ashishsingh/Desktop/filtered_visualizations\"  # Replace with the path to your visualisation images folder\n",
    "\n",
    "# Display dataset information\n",
    "print(f\"Number of RGB images: {len(os.listdir(rgb_dir))}\")\n",
    "print(f\"Number of masks: {len(os.listdir(mask_dir))}\")\n",
    "print(f\"Number of CSV files: {len(os.listdir(csv_dir))}\")\n",
    "print(f\"Number of visualizations: {len(os.listdir(vis_dir))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac860d5-d7e2-4f04-9218-3114fa48c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring and displaying segmented WSIs with ROIs and masks\n",
    "\n",
    "# Folder paths (different assigned variables as for a separate task)\n",
    "rgb_folder = \"/Users/ashishsingh/Desktop/filtered_rgbs\"  \n",
    "mask_folder = \"/Users/ashishsingh/Desktop/filtered_masks\" \n",
    "csv_folder = \"/Users/ashishsingh/Desktop/filtered_csvs\"\n",
    "vis_folder = \"/Users/ashishsingh/Desktop/filtered_visualizations\"\n",
    "\n",
    "# Function to load an image with error handling\n",
    "def load_image(file_path, convert_color=True):\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "    \n",
    "    image = cv2.imread(file_path)\n",
    "    if image is None:\n",
    "        print(f\"Failed to load image: {file_path}. Check the file format or integrity.\")\n",
    "        return None\n",
    "    \n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB) if convert_color else image\n",
    "\n",
    "# Process each RGB image in the folder\n",
    "for rgb_file in os.listdir(rgb_folder):\n",
    "    if rgb_file.endswith(\".png\"):\n",
    "        # File paths\n",
    "        rgb_image_path = os.path.join(rgb_folder, rgb_file)\n",
    "        mask_image_path = os.path.join(mask_folder, rgb_file.replace(\".png\", \".png\"))\n",
    "        vis_image_path = os.path.join(vis_folder, rgb_file.replace(\".png\", \".png\"))\n",
    "        csv_file_path = os.path.join(csv_folder, rgb_file.replace(\".png\", \".csv\"))\n",
    "\n",
    "        print(f\"Processing file: {rgb_file}\")\n",
    "        \n",
    "        # Load images\n",
    "        rgb_image = load_image(rgb_image_path)\n",
    "        mask_image = load_image(mask_image_path, convert_color=False)\n",
    "        vis_image = load_image(vis_image_path)\n",
    "\n",
    "        # Load CSV\n",
    "        if os.path.exists(csv_file_path):\n",
    "            csv_data = pd.read_csv(csv_file_path)\n",
    "        else:\n",
    "            print(f\"CSV file not found: {csv_file_path}\")\n",
    "            csv_data = None\n",
    "\n",
    "        # Ensure the CSV contains necessary columns\n",
    "        required_columns = {\"raw_group\", \"group\", \"type\", \"left\", \"right\", \"top\", \"bottom\", \"coords_x\", \"coords_y\"}\n",
    "        if csv_data is not None and not required_columns.issubset(csv_data.columns):\n",
    "            print(f\"The CSV file does not contain the required columns: {required_columns}\")\n",
    "            continue\n",
    "\n",
    "        # Display images\n",
    "        if rgb_image is not None:\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.imshow(rgb_image)\n",
    "            plt.title(f\"RGB Image: {rgb_file}\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "\n",
    "        if mask_image is not None:\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.imshow(mask_image, cmap=\"gray\")\n",
    "            plt.title(f\"Segmentation Mask: {rgb_file}\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "\n",
    "        if vis_image is not None:\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.imshow(vis_image)\n",
    "            plt.title(f\"Segmentation Mask Visualisation: {rgb_file}\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "\n",
    "        # Draw ROIs on the RGB image\n",
    "        if csv_data is not None and rgb_image is not None:\n",
    "            rgb_with_rois = rgb_image.copy()\n",
    "            for _, roi in csv_data.iterrows():\n",
    "                x1, x2, y1, y2 = roi[\"left\"], roi[\"right\"], roi[\"top\"], roi[\"bottom\"]\n",
    "                group = roi[\"group\"]\n",
    "                # Draw rectangle (colour blue for all ROIs)\n",
    "                cv2.rectangle(rgb_with_rois, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                # Optionally, annotate with group type\n",
    "                cv2.putText(rgb_with_rois, group, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "            # Display the RGB image with ROIs\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.imshow(rgb_with_rois)\n",
    "            plt.title(f\"RGB Image with ROIs: {rgb_file}\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b7ff68-a33b-4146-8098-957b77ec9363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory analysis of TILs\n",
    "\n",
    "# Paths to folders (different assigned variables as for a separate task)\n",
    "filtered_rgb_dir = \"/Users/ashishsingh/Desktop/filtered_rgbs\"\n",
    "filtered_vis_dir = \"/Users/ashishsingh/Desktop/filtered_visualizations\"\n",
    "filtered_mask_dir = \"/Users/ashishsingh/Desktop/filtered_masks\"\n",
    "filtered_csv_dir = \"/Users/ashishsingh/Desktop/filtered_csvs\"\n",
    "\n",
    "# Loop through all CSV files in the filtered_csv folder\n",
    "for csv_file in os.listdir(filtered_csv_dir):\n",
    "    if csv_file.endswith(\".csv\"):\n",
    "        csv_path = os.path.join(filtered_csv_dir, csv_file)\n",
    "        \n",
    "        # Load the CSV file\n",
    "        csv_data = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Filter for TILsCell\n",
    "        tils_data = csv_data[csv_data['group'] == 'TILsCell']\n",
    "\n",
    "        if tils_data.empty:\n",
    "            print(f\"No TILsCell regions found in {csv_file}.\")\n",
    "            continue\n",
    "        else:\n",
    "            # Calculate centroids of each TILsCell region\n",
    "            tils_data['centroid_x'] = (tils_data['left'] + tils_data['right']) / 2\n",
    "            tils_data['centroid_y'] = (tils_data['top'] + tils_data['bottom']) / 2\n",
    "\n",
    "            # Plot spatial distribution\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.scatter(tils_data['centroid_x'], tils_data['centroid_y'], alpha=0.7, color='green')\n",
    "            plt.title(f\"Spatial Distribution of TILsCell Centroids in {csv_file}\")\n",
    "            plt.xlabel(\"X Coordinate\")\n",
    "            plt.ylabel(\"Y Coordinate\")\n",
    "            plt.gca().invert_yaxis()  # Invert y-axis to match image coordinates\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "            # Calculate area of each TILsCell region\n",
    "            tils_data['area'] = (tils_data['right'] - tils_data['left']) * (tils_data['bottom'] - tils_data['top'])\n",
    "\n",
    "            # Calculate heterogeneity\n",
    "            area_mean = tils_data['area'].mean()\n",
    "            area_std = tils_data['area'].std()\n",
    "            area_coefficient_of_variation = area_std / area_mean\n",
    "\n",
    "            # Print analysis results\n",
    "            print(f\"TILsCell Spatial Analysis for {csv_file}:\")\n",
    "            print(f\"Number of TILsCell regions: {len(tils_data)}\")\n",
    "            print(f\"Mean area: {area_mean:.2f}\")\n",
    "            print(f\"Standard deviation of area: {area_std:.2f}\")\n",
    "            print(f\"Coefficient of variation (heterogeneity): {area_coefficient_of_variation:.2f}\")\n",
    "\n",
    "# Summary of processing\n",
    "print(\"\\nProcessing complete. Check the visualizations and results for each file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5df58f1-f250-4462-9ab6-478beced25aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring spatial distribution of cancer cells, TILs and stroma on a scatter plot\n",
    "\n",
    "# Define groups of interest\n",
    "groups_of_interest = [\n",
    "    'ActiveStromalCellNOS', \n",
    "    'ActiveTILsCell', \n",
    "    'CancerEpithelium', \n",
    "    'StromalCellNOS', \n",
    "    'TILsCell'\n",
    "]\n",
    "\n",
    "# Loop through all CSV files in the filtered_csv folder\n",
    "for csv_file in os.listdir(filtered_csv_dir):\n",
    "    if csv_file.endswith(\".csv\"):\n",
    "        csv_path = os.path.join(filtered_csv_dir, csv_file)\n",
    "        \n",
    "        # Load the CSV file\n",
    "        csv_data = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Initialise a plot\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        \n",
    "        # Loop through each group of interest\n",
    "        for group in groups_of_interest:\n",
    "            group_data = csv_data[csv_data['group'] == group]\n",
    "\n",
    "            if not group_data.empty:\n",
    "                # Calculate centroids\n",
    "                group_data['centroid_x'] = (group_data['left'] + group_data['right']) / 2\n",
    "                group_data['centroid_y'] = (group_data['top'] + group_data['bottom']) / 2\n",
    "\n",
    "                # Plot centroids\n",
    "                plt.scatter(\n",
    "                    group_data['centroid_x'], \n",
    "                    group_data['centroid_y'], \n",
    "                    alpha=0.7, \n",
    "                    label=group\n",
    "                )\n",
    "\n",
    "        # Customise plot\n",
    "        plt.title(f\"Spatial Distribution of Groups in {csv_file}\")\n",
    "        plt.xlabel(\"X Coordinate\")\n",
    "        plt.ylabel(\"Y Coordinate\")\n",
    "        plt.gca().invert_yaxis()  # Invert y-axis to match image coordinates\n",
    "        plt.legend(loc='best')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ace659-8b18-4e2f-9eb2-bb67d898599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing spread of cancer epithelium (spatial heterogeneity) using a simple coefficient of variation \n",
    "\n",
    "# Loop through all CSV files in the filtered_csv folder\n",
    "for csv_file in os.listdir(filtered_csv_dir):\n",
    "    if csv_file.endswith(\".csv\"):\n",
    "        csv_path = os.path.join(filtered_csv_dir, csv_file)\n",
    "        \n",
    "        # Load the CSV file\n",
    "        csv_data = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Filter for CancerEpithelium\n",
    "        cancer_data = csv_data[csv_data['group'] == 'CancerEpithelium']\n",
    "\n",
    "        if cancer_data.empty:\n",
    "            print(f\"No CancerEpithelium regions found in {csv_file}.\")\n",
    "            continue\n",
    "        else:\n",
    "            # Calculate centroids of each CancerEpithelium region\n",
    "            cancer_data['centroid_x'] = (cancer_data['left'] + cancer_data['right']) / 2\n",
    "            cancer_data['centroid_y'] = (cancer_data['top'] + cancer_data['bottom']) / 2\n",
    "\n",
    "            # Plot spatial distribution\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.scatter(cancer_data['centroid_x'], cancer_data['centroid_y'], alpha=0.7, color='blue')\n",
    "            plt.title(f\"Spatial Distribution of CancerEpithelium Centroids in {csv_file}\")\n",
    "            plt.xlabel(\"X Coordinate\")\n",
    "            plt.ylabel(\"Y Coordinate\")\n",
    "            plt.gca().invert_yaxis()  # Invert y-axis to match image coordinates\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "            # Calculate area of each CancerEpithelium region\n",
    "            cancer_data['area'] = (cancer_data['right'] - cancer_data['left']) * (cancer_data['bottom'] - cancer_data['top'])\n",
    "\n",
    "            # Calculate heterogeneity\n",
    "            area_mean = cancer_data['area'].mean()\n",
    "            area_std = cancer_data['area'].std()\n",
    "            area_coefficient_of_variation = area_std / area_mean\n",
    "\n",
    "            # Print analysis results\n",
    "            print(f\"CancerEpithelium Spatial Analysis for {csv_file}:\")\n",
    "            print(f\"Number of CancerEpithelium regions: {len(cancer_data)}\")\n",
    "            print(f\"Mean area: {area_mean:.2f}\")\n",
    "            print(f\"Standard deviation of area: {area_std:.2f}\")\n",
    "            print(f\"Coefficient of variation (heterogeneity): {area_coefficient_of_variation:.2f}\")\n",
    "\n",
    "# Summary of processing\n",
    "print(\"\\nProcessing complete. Check the visualizations and results for each file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c52a24-881b-4ba7-8ed9-1dfa4e4ea510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulating BCSS (Breast Cancer Semantic Segmentation) dataset to obtain breast cancer patients\n",
    "\n",
    "input_csv_path = \"/Users/ashishsingh/Desktop/bcss.csv\"\n",
    "\n",
    "# Path to save the filtered CSV\n",
    "output_csv_path = \"~/Desktop/filtered_brca.csv\"\n",
    "\n",
    "try:\n",
    "    # Load the CSV file\n",
    "    data = pd.read_csv(input_csv_path)\n",
    "\n",
    "    # Check if the \"type\" column exists\n",
    "    if \"type\" not in data.columns:\n",
    "        raise ValueError(\"The 'type' column is not found in the CSV file.\")\n",
    "\n",
    "    # Filter rows where \"type\" is \"BRCA\"\n",
    "    filtered_data = data[data[\"type\"] == \"BRCA\"]\n",
    "\n",
    "    # Save the filtered data to a new CSV file\n",
    "    filtered_data.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    print(f\"Filtered data has been saved to: {output_csv_path}\")\n",
    "    print(f\"Number of rows in the filtered data: {len(filtered_data)}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {input_csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc59246-dce5-4b22-a26d-995e7aa29bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulating available PanopTILs data aiming to identify and verify BCSS data\n",
    "\n",
    "csv_folder_path = \"/Users/ashishsingh/Desktop/filtered_csvs\"\n",
    "\n",
    "# Path to save the new CSV file\n",
    "output_csv_path = \"~/Desktop/panoptils_to_bcss.csv\"\n",
    "\n",
    "try:\n",
    "    # Initialise a list to store the trimmed file names\n",
    "    trimmed_names = []\n",
    "\n",
    "    # Loop through all files in the folder\n",
    "    for file_name in os.listdir(csv_folder_path):\n",
    "        # Process only CSV files\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            # Extract the first 12 characters of the file name (excluding the extension)\n",
    "            trimmed_name = file_name[:12]\n",
    "            trimmed_names.append(trimmed_name)\n",
    "\n",
    "    # Create a DataFrame from the trimmed names\n",
    "    trimmed_names_df = pd.DataFrame({\"trimmed_names\": trimmed_names})\n",
    "\n",
    "    # Save the DataFrame to a new CSV file on the Desktop\n",
    "    trimmed_names_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    print(f\"New CSV file with trimmed names has been saved to: {output_csv_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Folder not found: {csv_folder_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b5d3c9-5b26-4b66-bae3-5f828713ca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying relevant data points from BCSS\n",
    "\n",
    "filtered_brca_path = \"~/Desktop/filtered_brca.csv\" \n",
    "panoptils_to_bcss_path = \"~/Desktop/panoptils_to_bcss.csv\"\n",
    "\n",
    "try:\n",
    "    # Load the CSV files\n",
    "    filtered_brca_data = pd.read_csv(filtered_brca_path)\n",
    "    panoptils_to_bcss_data = pd.read_csv(panoptils_to_bcss_path)\n",
    "\n",
    "    # Check if the required columns exist\n",
    "    if \"bcr_patient_barcode\" not in filtered_brca_data.columns:\n",
    "        raise ValueError(\"The 'bcr_patient_barcode' column is not found in the filtered_brca CSV file.\")\n",
    "    if \"trimmed_names\" not in panoptils_to_bcss_data.columns:\n",
    "        raise ValueError(\"The 'trimmed_names' column is not found in the panoptils_to_bcss CSV file.\")\n",
    "\n",
    "    # Read and strip spaces from the columns\n",
    "    bcr_patient_barcodes = filtered_brca_data[\"bcr_patient_barcode\"].str.replace(\" \", \"\").unique()\n",
    "    trimmed_names = panoptils_to_bcss_data[\"trimmed_names\"].str.replace(\" \", \"\").unique()\n",
    "\n",
    "    # Find similar values\n",
    "    similar_values = set(bcr_patient_barcodes) & set(trimmed_names)\n",
    "\n",
    "    # Display the result\n",
    "    print(f\"Number of similar values: {len(similar_values)}\")\n",
    "    if similar_values:\n",
    "        print(\"Similar values:\")\n",
    "        print(similar_values)\n",
    "    else:\n",
    "        print(\"No similar values found.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06324b6-275b-488f-8db7-fc04e21662bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying relevant data from BCSS\n",
    "\n",
    "filtered_csvs_path = \"/Users/ashishsingh/Desktop/filtered_csvs\" \n",
    "inter_csvs_path = os.path.expanduser(\"~/Desktop/inter_csvs\") \n",
    "\n",
    "\n",
    "# Iterate through the CSV files in the filtered_csvs folder\n",
    "for csv_file in os.listdir(filtered_csvs_path):\n",
    "    if csv_file.endswith(\".csv\"):\n",
    "        # Extract the first 12 characters of the file name (excluding the extension)\n",
    "        new_file_name = f\"{csv_file[:12]}.csv\"\n",
    "        \n",
    "        # Paths for the source and destination\n",
    "        source_file = os.path.join(filtered_csvs_path, csv_file)\n",
    "        destination_file = os.path.join(inter_csvs_path, new_file_name)\n",
    "        \n",
    "        # Copy and rename the file\n",
    "        shutil.copy(source_file, destination_file)\n",
    "        print(f\"Processed: {csv_file} -> {new_file_name}\")\n",
    "\n",
    "print(\"Renaming and processing complete. Files saved to the inter_csvs folder.\")\n",
    "\n",
    "# Paths\n",
    "inter_csvs_path = os.path.expanduser(\"~/Desktop/inter_csvs\")  # Path to the inter_csvs folder\n",
    "similar_values_path = os.path.expanduser(\"~/Desktop/similar_values_output.csv\")  # Path to the similar_values_output.csv file\n",
    "\n",
    "try:\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(inter_csvs_path):\n",
    "        raise FileNotFoundError(f\"The folder '{inter_csvs_path}' does not exist.\")\n",
    "\n",
    "    # Get all file names in the folder and remove the '.csv' extension\n",
    "    file_names = [\n",
    "        os.path.splitext(file)[0] for file in os.listdir(inter_csvs_path)\n",
    "        if os.path.isfile(os.path.join(inter_csvs_path, file)) and file.endswith(\".csv\")\n",
    "    ]\n",
    "\n",
    "    # Load similar_values_output.csv\n",
    "    similar_values_df = pd.read_csv(similar_values_path)\n",
    "\n",
    "    if \"Similar Values\" not in similar_values_df.columns:\n",
    "        raise ValueError(\"The 'Similar Values' column is not found in the similar_values_output file.\")\n",
    "\n",
    "    # Extract the values from the column and strip spaces\n",
    "    similar_values = similar_values_df[\"Similar Values\"].str.strip().tolist()\n",
    "\n",
    "    # Compare the two lists\n",
    "    file_names_set = set(file_names)\n",
    "    similar_values_set = set(similar_values)\n",
    "\n",
    "    if file_names_set == similar_values_set:\n",
    "        print(\"The file names in 'inter_csvs' are equal to the rows in 'similar_values_output.csv'.\")\n",
    "    else:\n",
    "        print(\"The file names in 'inter_csvs' do not match the rows in 'similar_values_output.csv'.\")\n",
    "        print(\"Files in 'inter_csvs' but not in 'similar_values_output.csv':\")\n",
    "        print(file_names_set - similar_values_set)\n",
    "        print(\"Values in 'similar_values_output.csv' but not in 'inter_csvs':\")\n",
    "        print(similar_values_set - file_names_set)\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66525d2f-be43-466a-9846-b11d36f8140d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulating BCSS csv file to extract ID and Disease-Free Interval (DFI) data\n",
    "\n",
    "filtered_brca_path = os.path.expanduser(\"~/Desktop/filtered_brca.csv\")  # Path to the filtered_brca file\n",
    "output_path = os.path.expanduser(\"~/Desktop/bcss-outcomes.csv\")  # Path to save the new file\n",
    "\n",
    "try:\n",
    "    # Load the filtered_brca CSV file\n",
    "    filtered_brca_df = pd.read_csv(filtered_brca_path)\n",
    "\n",
    "    # Check if the required columns exist\n",
    "    required_columns = [\"bcr_patient_barcode\", \"PFI.time.1\"]\n",
    "    for column in required_columns:\n",
    "        if column not in filtered_brca_df.columns:\n",
    "            raise ValueError(f\"The column '{column}' is not found in the filtered_brca file.\")\n",
    "\n",
    "    # Extract the required columns\n",
    "    extracted_df = filtered_brca_df[required_columns]\n",
    "\n",
    "    # Save the extracted columns as a new CSV file\n",
    "    extracted_df.to_csv(output_path, index=False)\n",
    "    print(f\"New file 'bcss-outcomes.csv' saved to the Desktop.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8147c0d-9cb8-447a-a148-b2f0546af215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 1318 WSI\n",
    "# Calculating cofficients of variability for cancer epithelium in each regions of interest\n",
    "\n",
    "# Dictionary to store results\n",
    "results = []\n",
    "\n",
    "# Iterate through all .png files in the filtered_rgbs folder\n",
    "for image_file in os.listdir(filtered_rgb_dir):\n",
    "    if image_file.endswith(\".png\"):\n",
    "        image_path = os.path.join(filtered_rgb_dir, image_file)\n",
    "\n",
    "        # Open the image\n",
    "        with Image.open(image_path) as img:\n",
    "            image_array = np.array(img)\n",
    "\n",
    "        # Mask for cancer epithelium (assuming it's the first channel)\n",
    "        epithelium_mask = image_array[:, :, 0] > 0  # Non-zero values represent cancer epithelium\n",
    "\n",
    "        # Calculate coefficient of variation for cancer epithelium\n",
    "        epithelium_values = image_array[:, :, 0][epithelium_mask]\n",
    "        if len(epithelium_values) > 0:\n",
    "            mean_value = np.mean(epithelium_values)\n",
    "            std_value = np.std(epithelium_values)\n",
    "            coefficient_of_variation = std_value / mean_value\n",
    "        else:\n",
    "            coefficient_of_variation = np.nan  # Assign NaN if no epithelium is detected\n",
    "\n",
    "        # Store results\n",
    "        results.append({\"File Name\": image_file, \"Coefficient of Variation\": coefficient_of_variation})\n",
    "\n",
    "# Save results to a CSV file\n",
    "output_csv_path = os.path.expanduser(\"~/Desktop/cancer_epithelium_heterogeneity_all.csv\")\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_csv_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae030b51-cf32-417a-8f47-6528a2d13bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulating names to match with BCSS\n",
    "\n",
    "# Path to the input CSV file\n",
    "input_csv_path = os.path.expanduser(\"~/Desktop/cancer_epithelium_heterogeneity_all.csv\")\n",
    "\n",
    "# Path to the output CSV file\n",
    "output_csv_path = os.path.expanduser(\"~/Desktop/cancer_epithelium_heterogeneity_modified.csv\")\n",
    "\n",
    "try:\n",
    "    # Load the CSV file\n",
    "    heterogeneity_df = pd.read_csv(input_csv_path)\n",
    "\n",
    "    if \"File Name\" not in heterogeneity_df.columns:\n",
    "        raise ValueError(\"The 'File Name' column is not found in the input CSV file.\")\n",
    "\n",
    "    # Modify the \"File Name\" column to keep only the first 12 characters\n",
    "    heterogeneity_df[\"File Name\"] = heterogeneity_df[\"File Name\"].str[:12]\n",
    "\n",
    "    # Save the updated DataFrame to a new CSV file\n",
    "    heterogeneity_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    print(f\"File names modified and saved to {output_csv_path}.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f04cf25-d328-46cb-ba81-34156a96368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 118 patients\n",
    "# Calculating mean cofficients of variability for cancer epithelium, grouping by BCSS patient ID\n",
    "\n",
    "# Path to the input CSV file\n",
    "input_csv_path = os.path.expanduser(\"~/Desktop/cancer_epithelium_heterogeneity_modified.csv\")\n",
    "\n",
    "# Path to the output CSV file\n",
    "output_csv_path = os.path.expanduser(\"~/Desktop/cancer_epithelium_heterogeneity_combined.csv\")\n",
    "\n",
    "try:\n",
    "    # Load the CSV file\n",
    "    heterogeneity_df = pd.read_csv(input_csv_path)\n",
    "\n",
    "    if \"File Name\" not in heterogeneity_df.columns or \"Coefficient of Variation\" not in heterogeneity_df.columns:\n",
    "        raise ValueError(\"The required columns ('File Name' and 'Coefficient of Variation') are not found in the input CSV file.\")\n",
    "\n",
    "    # Combine rows with the same \"File Name\" and calculate the mean of \"Coefficient of Variation\"\n",
    "    combined_df = heterogeneity_df.groupby(\"File Name\", as_index=False)[\"Coefficient of Variation\"].mean()\n",
    "\n",
    "    # Save the combined DataFrame to a new CSV file\n",
    "    combined_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    print(f\"Combined results saved to {output_csv_path}.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec37843c-12e6-4d20-90ec-1935a97d84f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining coefficients of variability from PanopTILs with PFI from BCSS\n",
    "\n",
    "# Paths to the input files\n",
    "heterogeneity_combined_path = os.path.expanduser(\"~/Desktop/cancer_epithelium_heterogeneity_combined.csv\")\n",
    "bcss_outcomes_path = os.path.expanduser(\"~/Desktop/bcss-outcomes.csv\")\n",
    "\n",
    "# Path to the output file\n",
    "output_csv_path = os.path.expanduser(\"~/Desktop/ml-data.csv\")\n",
    "\n",
    "try:\n",
    "    # Load the CSV files\n",
    "    heterogeneity_df = pd.read_csv(heterogeneity_combined_path)\n",
    "    bcss_outcomes_df = pd.read_csv(bcss_outcomes_path)\n",
    "\n",
    "    # Ensure required columns are present\n",
    "    required_columns_heterogeneity = [\"File Name\", \"Coefficient of Variation\"]\n",
    "    required_columns_outcomes = [\"bcr_patient_barcode\", \"PFI.time.1\"]\n",
    "\n",
    "    for column in required_columns_heterogeneity:\n",
    "        if column not in heterogeneity_df.columns:\n",
    "            raise ValueError(f\"The column '{column}' is not found in the heterogeneity file.\")\n",
    "\n",
    "    for column in required_columns_outcomes:\n",
    "        if column not in bcss_outcomes_df.columns:\n",
    "            raise ValueError(f\"The column '{column}' is not found in the outcomes file.\")\n",
    "\n",
    "    # Merge the dataframes\n",
    "    combined_df = pd.merge(\n",
    "        bcss_outcomes_df,\n",
    "        heterogeneity_df,\n",
    "        left_on=\"bcr_patient_barcode\",\n",
    "        right_on=\"File Name\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "    # Retain only necessary columns\n",
    "    combined_df = combined_df[[\"bcr_patient_barcode\", \"PFI.time.1\", \"Coefficient of Variation\"]]\n",
    "\n",
    "    # Save the combined DataFrame to a new CSV file\n",
    "    combined_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    print(f\"Combined data saved to {output_csv_path}.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22696d7b-4231-4770-afd7-a63beb6e14fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying machine learning\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Load the dataset\n",
    "data_path = \"~/Desktop/ml-data.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Feature (independent variable) and target (dependent variable)\n",
    "X = data[[\"Coefficient of Variation\"]].values\n",
    "y = data[\"PFI.time.1\"].apply(lambda x: 1 if x > np.median(data[\"PFI.time.1\"]) else 0).values  # Binary classification\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Support Vector Machine\": SVC(probability=True, random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42)\n",
    "}\n",
    "\n",
    "# Hyperparameter grids for each model\n",
    "param_grids = {\n",
    "    \"Support Vector Machine\": {\n",
    "        \"C\": [0.1, 1, 10, 100],\n",
    "        \"kernel\": [\"linear\", \"rbf\"],\n",
    "        \"gamma\": [\"scale\", \"auto\"]\n",
    "    },\n",
    "    \"Logistic Regression\": {\n",
    "        \"C\": [0.1, 1, 10, 100],\n",
    "        \"solver\": [\"liblinear\", \"lbfgs\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform Bayesian-like grid search to find the best hyperparameters\n",
    "best_models = {}\n",
    "best_f1_scores = {}\n",
    "confusion_matrices = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Tuning hyperparameters for {model_name}...\")\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grids[model_name],\n",
    "        scoring=\"f1\",\n",
    "        cv=5,\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    best_f1_scores[model_name] = f1\n",
    "    confusion_matrices[model_name] = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Best F1 Score for {model_name}: {f1:.4f}\")\n",
    "\n",
    "# Select the best model based on F1 score\n",
    "best_model_name = max(best_f1_scores, key=best_f1_scores.get)\n",
    "print(f\"\\nBest Model: {best_model_name} with F1 Score: {best_f1_scores[best_model_name]:.4f}\")\n",
    "\n",
    "# Print confusion matrices for all models\n",
    "for model_name, matrix in confusion_matrices.items():\n",
    "    print(f\"\\nConfusion Matrix for {model_name}:\")\n",
    "    print(matrix)\n",
    "\n",
    "# Final results\n",
    "print(\"\\nClassification Report for Best Model:\")\n",
    "print(classification_report(y_test, best_models[best_model_name].predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb4d7f7-a2e4-4e3d-af5b-5032f8d5c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting survival curves\n",
    "\n",
    "from lifelines import KaplanMeierFitter\n",
    "\n",
    "# Load the dataset\n",
    "data_path = \"~/Desktop/ml-data.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Check for required columns\n",
    "if \"Coefficient of Variation\" not in data.columns or \"PFI.time.1\" not in data.columns:\n",
    "    raise ValueError(\"Required columns are not present in the dataset.\")\n",
    "\n",
    "# Truncate data at time 1000 to exclude outliers\n",
    "data = data[data[\"PFI.time.1\"] <= 1500]\n",
    "\n",
    "# Define a threshold for \"low\" and \"high\" Coefficient of Variation\n",
    "threshold = data[\"Coefficient of Variation\"].median()  # Median as the threshold\n",
    "data[\"Risk Group\"] = np.where(data[\"Coefficient of Variation\"] <= threshold, \"Low\", \"High\")\n",
    "\n",
    "# Prepare data for Kaplan-Meier fitting\n",
    "time = data[\"PFI.time.1\"]\n",
    "event_observed = np.ones(len(time))  # Assuming all patients are observed (no censored data)\n",
    "\n",
    "# Create Kaplan-Meier fitter objects\n",
    "kmf_low = KaplanMeierFitter()\n",
    "kmf_high = KaplanMeierFitter()\n",
    "\n",
    "# Fit survival curves for each group\n",
    "low_group = data[data[\"Risk Group\"] == \"Low\"]\n",
    "high_group = data[data[\"Risk Group\"] == \"High\"]\n",
    "\n",
    "kmf_low.fit(durations=low_group[\"PFI.time.1\"], event_observed=np.ones(len(low_group)), label=\"Low Coefficient of Variation of Cancer Epithelium\")\n",
    "kmf_high.fit(durations=high_group[\"PFI.time.1\"], event_observed=np.ones(len(high_group)), label=\"High Coefficient of Variation of Cancer Epithelium\")\n",
    "\n",
    "# Plot Kaplan-Meier survival curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "kmf_low.plot_survival_function(ci_show=False)\n",
    "kmf_high.plot_survival_function(ci_show=False)\n",
    "\n",
    "# Add plot details\n",
    "plt.title(\"Kaplan-Meier Curves for Progression-Free Interval\")\n",
    "plt.xlabel(\"Progression-Free Interval in Days\")\n",
    "plt.ylabel(\"Survival Probability\")\n",
    "plt.xlim(0, 1000)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b409191-3e0c-4e57-bfed-c6aebfcd551e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
